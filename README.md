# 프로젝트 개요
    이 프로젝트는 실시간 모니터링 시스템을 구축하기 위해 Kafka, Redis, Spring Batch, 그리고 WebSocket을 사용합니다. 데이터는 Kafka를 통해 실시간으로 스트리밍되고, Redis는 데이터 저장소로 사용되며, Spring Batch는 배치 작업을 수행합니다. WebSocket은 실시간 데이터 업데이트를 위해 사용됩니다.

## 데이터 흐름
### 데이터 생산:
    데이터는 Kafka의 Producer를 통해 생성됩니다.
    Kafka는 분산 메시징 시스템으로, 데이터를 다양한 Consumer에게 스트리밍합니다.
### 데이터 스트리밍:
    생성된 데이터는 Kafka의 토픽에 게시됩니다.
    Kafka Broker는 데이터를 관리하며, 토픽을 통해 데이터를 분산합니다.
### 데이터 소비:
    Spring Boot 애플리케이션의 Kafka Consumer가 Kafka 토픽에서 데이터를 읽어들입니다.
    읽어들인 데이터는 Redis에 저장됩니다.
    Spring Batch 작업이 주기적으로 Redis에서 데이터를 가져와 배치 처리를 수행합니다.
### 실시간 업데이트:
    WebSocket을 통해 클라이언트는 실시간으로 데이터 업데이트를 받습니다.
    Spring Boot 애플리케이션은 WebSocket을 사용하여 클라이언트에게 실시간으로 데이터 변경 사항을 전송합니다.
    Docker와 Kubernetes 설정

## Docker 설정
    Docker는 컨테이너화된 애플리케이션을 실행하기 위한 플랫폼입니다. Docker Compose는 여러 컨테이너를 정의하고 실행할 수 있는 도구입니다.

### docker-compose.yml:
    Zookeeper: Kafka가 분산 시스템으로 동작할 수 있도록 관리합니다.
    Kafka: 메시징 시스템으로, 데이터 스트리밍을 처리합니다.
    Redis: 인메모리 데이터베이스로, 실시간 데이터 저장소로 사용됩니다.
    

### Kubernetes 설정
    Kubernetes는 컨테이너화된 애플리케이션의 배포, 스케일링, 관리를 자동화하는 플랫폼입니다. 각 애플리케이션 구성 요소를 관리하기 위해 다양한 YAML 파일이 사용됩니다.

### kubernetes-deployment.yaml:
    Deployment: 애플리케이션의 특정 개수를 실행하고, 업데이트 및 롤백을 관리합니다.
    Service: 외부 트래픽을 내부 애플리케이션으로 라우팅합니다.
    이 파일은 애플리케이션의 배포와 서비스 설정을 정의합니다. Deployment는 애플리케이션의 인스턴스를 관리하고, Service는 외부에서 접근할 수 있도록 포트를 노출합니다.

### 데이터 흐름 순서
    Kafka Producer가 데이터를 생성하고 Kafka Broker에 게시합니다.
    Kafka Broker는 데이터를 토픽으로 분산합니다.
    Spring Boot 애플리케이션의 Kafka Consumer가 Kafka 토픽에서 데이터를 읽어 Redis에 저장합니다.
    Spring Batch 작업이 주기적으로 Redis에서 데이터를 가져와 처리합니다.
    WebSocket을 통해 클라이언트는 실시간으로 데이터 업데이트를 받습니다.
    이 모든 과정은 Docker와 Kubernetes를 통해 관리되고 오케스트레이션됩니다. Docker는 각 서비스의 컨테이너를 관리하고, Kubernetes는 이러한 컨테이너들을 배포, 스케일링, 업그레이드 등의 작업을 자동화합니다.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
### Kafka와 Zookeeper의 관계 및 이유
    Kafka는 분산 메시징 시스템으로, 데이터를 스트리밍하고 처리하는 데 사용됩니다. Kafka를 실행할 때 Zookeeper와 함께 사용하는 이유는 다음과 같습니다:
    메타데이터 관리: Zookeeper는 Kafka의 메타데이터(브로커 정보, 토픽, 파티션 정보 등)를 저장하고 관리합니다.
    브로커 관리: Zookeeper는 Kafka 클러스터의 브로커를 추적하고 관리합니다. 브로커가 추가되거나 제거될 때 이를 클러스터 내 다른 브로커들에게 알립니다.
    리더 선출: Zookeeper는 파티션의 리더를 선출하는 데 사용됩니다. 각 파티션에는 여러 복제본이 있으며, 리더는 클라이언트 요청을 처리하는 복제본입니다.
    구성 변경: Zookeeper는 Kafka의 구성 변경 사항을 브로커들에게 전달합니다.
## Kafka 용어 설명
### 브로커(Broker):
    Kafka 클러스터의 서버 인스턴스를 의미합니다.
    데이터 저장소 역할을 하며, 데이터를 수신하고 디스크에 저장하고, 데이터를 소비자에게 제공합니다.
    여러 브로커가 클러스터를 구성하여 확장성과 가용성을 높입니다.
### 토픽(Topic):
    데이터 스트림의 범주나 이름입니다.
    프로듀서가 데이터를 게시하는 논리적 채널입니다.
    토픽은 여러 파티션으로 나눠질 수 있습니다.
### 파티션(Partition):
    토픽의 물리적 분할입니다.
    각 파티션은 로그 형태로 데이터가 저장되며, 각 메시지는 오프셋이라는 고유한 ID를 가집니다.
    파티션을 통해 데이터가 분산 저장되고, 병렬 처리가 가능해집니다.
### 프로듀서(Producer):
    데이터를 생성하고 Kafka 토픽에 데이터를 게시하는 역할을 합니다.
    데이터를 토픽의 파티션에 분산하여 저장합니다.
### 컨슈머(Consumer):
    Kafka 토픽에서 데이터를 읽어오는 역할을 합니다.
    컨슈머 그룹을 구성하여 여러 컨슈머가 동일한 토픽의 데이터를 병렬로 처리할 수 있습니다.
### 컨슈머 그룹(Consumer Group):
    하나 이상의 컨슈머가 그룹을 이루어 데이터를 처리하는 방식입니다.
    각 파티션은 컨슈머 그룹 내의 하나의 컨슈머에게만 할당됩니다.
### 오프셋(Offset):
파티션 내의 각 메시지에 대한 고유한 ID입니다.
컨슈머는 오프셋을 사용하여 어느 위치에서부터 데이터를 읽어야 하는지 추적합니다.
### 레플리카(Replica):
    파티션의 복제본입니다.
    브로커 간의 데이터 손실을 방지하고 가용성을 높입니다.
    리더와 팔로워 레플리카로 구분됩니다.
### 리더(Leader):
    파티션의 주된 복제본으로, 모든 읽기 및 쓰기 요청을 처리합니다.
    각 파티션은 하나의 리더를 가집니다.
### 팔로워(Follower):
    파티션의 복제본 중 리더가 아닌 복제본입니다.
    리더의 데이터를 복제하고, 리더가 실패할 경우 새로운 리더로 승격될 수 있습니다.

### Docker와 Kubernetes 설정
    Docker Compose
    Docker Compose는 여러 컨테이너를 정의하고 실행할 수 있는 도구입니다. 이 프로젝트에서는 Kafka, Zookeeper, Redis를 실행합니다.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
## Docker 기본 용어
### 이미지 (Image):
    컨테이너의 실행 파일 시스템을 포함한 불변 템플릿입니다.
    응용 프로그램과 그 종속성을 포함합니다.
### 컨테이너 (Container):
    이미지를 실행한 인스턴스입니다.
    애플리케이션을 격리된 환경에서 실행할 수 있습니다.
### 도커파일 (Dockerfile):
    이미지를 생성하기 위한 설정 파일입니다.
    이미지 빌드 시 실행될 명령어들을 정의합니다.
### 도커 허브 (Docker Hub):
    도커 이미지를 저장하고 공유하는 레지스트리 서비스입니다.
    공용 및 개인 저장소를 제공합니다.
### 도커 컴포즈 (Docker Compose):
    여러 컨테이너를 정의하고 실행할 수 있는 도구입니다.
    docker-compose.yml 파일을 사용하여 여러 컨테이너의 설정을 한 번에 관리합니다.
## Kubernetes 기본 용어
### 노드 (Node):
    Kubernetes 클러스터를 구성하는 서버입니다.
    마스터 노드와 워커 노드로 나뉩니다.
### 파드 (Pod):
    Kubernetes에서 가장 작은 배포 단위입니다.
    하나 이상의 컨테이너를 포함합니다.
    동일한 네트워크와 저장소를 공유합니다.
### 디플로이먼트 (Deployment):
    애플리케이션의 배포와 관리를 담당합니다.
    파드의 생성, 업데이트, 삭제를 관리합니다.
### 서비스 (Service):
    클러스터 내부 또는 외부에서 접근할 수 있도록 파드를 노출합니다.
    로드 밸런싱 기능을 제공합니다.
### 컨피그맵 (ConfigMap):
    설정 데이터를 키-값 쌍으로 저장합니다.
    파드에서 환경 변수를 통해 사용할 수 있습니다.
### 시크릿 (Secret):
    민감한 데이터를 키-값 쌍으로 저장합니다.
    암호화된 데이터를 파드에서 사용할 수 있습니다.
### 볼륨 (Volume):
    파드가 사용하는 디스크 공간을 제공합니다.
    데이터를 저장하고 파드 재시작 시에도 데이터를 유지할 수 있습니다.
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


### 실행중인 Docker 컨테이너 목록 확인
    docker ps

### Kafka 컨테이너에 접속
    docker exec -it 71d1db7c61c5 /bin/sh

### Docker Compose 서비스 재시작
    docker-compose down
    docker-compose up -d

### Kafka 브로커 로그 확인
    docker logs <kafka-container-id>

### 모든 Docker 컨테이너 중지
    docker stop $(docker ps -q)
    
### 필요하지 않은 Docker 컨테이너 삭제
    docker rm $(docker ps -a -q)

### Kafka 및 Zookeeper 컨테이너 재시작:
docker restart <kafka-container-id>
docker restart <zookeeper-container-id>
